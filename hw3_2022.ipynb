{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-06d3e5bf55c941ae",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "tags": []
   },
   "source": [
    "# Homework set 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-736ff6bc3e0d0696",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Please **submit this Jupyter notebook through Canvas** no later than **Mon Nov. 21, 9:00**. **Submit the notebook file with your answers (as .ipynb file) and a pdf printout. The pdf version can be used by the teachers to provide feedback. A pdf version can be made using the save and export option in the Jupyter Lab file menu.**\n",
    "\n",
    "Homework is in **groups of two**, and you are expected to hand in original work. Work that is copied from another group will not be accepted."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b13bc5ed16bce8e0",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Exercise 0\n",
    "Write down the names + student ID of the people in your group."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fd464f55ba436b1c",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Karin Brinksma 13919938 Dominique Weltevreden 12161160"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-b5a7855ecca9f6be",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Run the following cell to import NumPy and Pyplot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import linalg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise you will study the accuracy of several methods for computing the QR decomposition. You are asked to implement these methods yourself. (However, when testing your implementation you may compare with an external implementation.)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (a) \n",
    "Implement the classical and modified Gram-Schmidt procedures for computing the QR decomposition.\n",
    "\n",
    "Include a short documentation using triple quotes: describe at least the input and the output, and whether the code modifies the input matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.   1.  -3. ]\n",
      " [ 3.   2.   1. ]\n",
      " [-2.   0.5  2.5]\n",
      " [-8.  -6.   2. ]]\n",
      "[[ 1.   1.  -3. ]\n",
      " [ 3.   2.   1. ]\n",
      " [-2.   0.5  2.5]\n",
      " [-8.  -6.   2. ]]\n",
      "Should be identity matrix [[ 1.     0.952 -0.   ]\n",
      " [ 0.952  1.     0.114]\n",
      " [-0.     0.114  1.   ]]\n",
      "[[ 1.   1.  -3. ]\n",
      " [ 3.   2.   1. ]\n",
      " [-2.   0.5  2.5]\n",
      " [-8.  -6.   2. ]]\n",
      "Should be identity matrix [[ 1.  0. -0.]\n",
      " [ 0.  1. -0.]\n",
      " [-0. -0.  1.]]\n"
     ]
    }
   ],
   "source": [
    "def classical_gram_schmidt(A):\n",
    "    \"\"\"\n",
    "    QR decomposition using classical Gram-Schmidt procedures.\n",
    "    Input: \n",
    "    A = m x n matrix that forms a basis (l.i. columns). m must be larger than n\n",
    "    \n",
    "    Returns:\n",
    "    R = Upper triangular matrix\n",
    "    Q = Orthogonal matrix \n",
    "    \n",
    "    Taken largely from: https://gist.github.com/fabianp/1073728 & \n",
    "    \"\"\"\n",
    "    # Get shape of matrix A\n",
    "    m, n = np.shape(A)\n",
    "    assert m >= n, \"Matrix should have more or equal rows to columns\"\n",
    "    \n",
    "    # Make empty QR matrixes in right form; R with 0 because we only fill in the rest of the squares\n",
    "    # R is a square matrix; Q is m x n\n",
    "    R = np.zeros((n, n))\n",
    "    Q = np.array(A, dtype= 'float64')\n",
    "    \n",
    "    # Take the first column of A to be the first vector and normalize it to form an orthogonal basis\n",
    "    # The top-left value for R is the norm of the first column of A\n",
    "   \n",
    "    Q[:, 0] = A[:, 0] / linalg.norm(A[:, 0])\n",
    "    R[0, 0] = A[:, 0] @ Q[:, 0]\n",
    "    \n",
    "    # Loop over the rest of the columns\n",
    "    for k in range(1, n):\n",
    "        \n",
    "        # Get the current column being transformed into an orthogonal vector\n",
    "        a = A[:, k]\n",
    "        \n",
    "        # Set u as a\n",
    "        u = a\n",
    "    \n",
    "        # Calculate u through the iterative process of multiplying before u and a vectors\n",
    "        for e_k in range(0, k-1):\n",
    "        \n",
    "            e_prev_k = Q[:, e_k]\n",
    "          \n",
    "            # Calculate the top row of R by taking the current a vector and multiplying it with previous e_ks\n",
    "            R[e_k, k] = (a @ e_prev_k)\n",
    "            \n",
    "            # Calculate u\n",
    "            u = u - ((a @ e_prev_k) * e_prev_k)\n",
    "            \n",
    "            # Check linear independence\n",
    "            assert not np.array_equal(u, np.zeros(u.shape)), \"The column vectors are not linearly independent\"\n",
    "        \n",
    "        # Normalize the u vector by the norm of u\n",
    "        Q[:, k] = u / (linalg.norm(u) ) \n",
    "        \n",
    "        # Get current R for this k\n",
    "        R[k, k] = a @ Q[:, k]\n",
    "             \n",
    "        \n",
    "    return Q, R\n",
    "\n",
    "def modified_gram_schmidt(A):\n",
    "    \"\"\"For m x n matrix return Q and R components of QR decomposition using\n",
    "    the modified Gram-Schmidt process, where R is n x n upper triangular\n",
    "    and Q is m x n and have orthogonal columns.\n",
    "    \n",
    "    https://github.com/kajetanj/QR-MGS-decomp/blob/master/decompose.py\n",
    "    \"\"\"\n",
    "    m, n = np.shape(A)\n",
    "    assert m >= n, \"Matrix should have more or equal rows to columns\"\n",
    "    \n",
    "\n",
    "    Q = np.array(A, dtype='float64')\n",
    "    R = np.zeros((n, n))\n",
    "    \n",
    "    for k in range(n):\n",
    "        a_k = Q[:, k]\n",
    "        R[k,k] = np.linalg.norm(a_k)\n",
    "        a_k /= R[k, k]\n",
    "        \n",
    "        for i in range(k+1, n):\n",
    "            a_i = Q[:, i]\n",
    "            R[k,i] = np.transpose(a_k) @ a_i\n",
    "            a_i -= R[k, i] * a_k\n",
    "\n",
    "    return Q, R\n",
    "\n",
    "matrix = np.array([\n",
    "            [1.0, 1.0, -3.0],\n",
    "            [3.0, 2.0, 1.0],\n",
    "            [-2.0, 0.5, 2.5],\n",
    "            [-8, -6, 2]\n",
    "        ])\n",
    "calc_q, calc_r = classical_gram_schmidt(matrix)\n",
    "# Dit gaat goed\n",
    "print(calc_q @ calc_r)\n",
    "print(matrix)\n",
    "# Dit niet; zou identity matrix moeten zijn, is het duidelijk niet\n",
    "print(\"Should be identity matrix\", np.around(calc_q.T @ calc_q, 3))\n",
    "mod_q, mod_r = modified_gram_schmidt(matrix)\n",
    "print(mod_q @ mod_r)\n",
    "print(\"Should be identity matrix\", np.around(mod_q.T @ mod_q, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QR_Decomposition(A):\n",
    "    n, m = A.shape # get the shape of A\n",
    "\n",
    "    Q = np.empty((n, n)) # initialize matrix Q\n",
    "    u = np.empty((n, n)) # initialize matrix u\n",
    "\n",
    "    u[:, 0] = A[:, 0]\n",
    "    Q[:, 0] = u[:, 0] / np.linalg.norm(u[:, 0])\n",
    "\n",
    "    for i in range(1, n):\n",
    "\n",
    "        u[:, i] = A[:, i]\n",
    "        for j in range(i):\n",
    "            u[:, i] -= (A[:, i] @ Q[:, j]) * Q[:, j] # get each u vector\n",
    "\n",
    "        Q[:, i] = u[:, i] / np.linalg.norm(u[:, i]) # compute each e vetor\n",
    "\n",
    "    R = np.zeros((n, m))\n",
    "    for i in range(n):\n",
    "        for j in range(i, m):\n",
    "            R[i, j] = A[:, j] @ Q[:, i]\n",
    "\n",
    "    return Q, R\n",
    "\n",
    "def diag_sign(A):\n",
    "    \"Compute the signs of the diagonal of matrix A\"\n",
    "\n",
    "    D = np.diag(np.sign(np.diag(A)))\n",
    "\n",
    "    return D\n",
    "\n",
    "def adjust_sign(Q, R):\n",
    "    \"\"\"\n",
    "    Adjust the signs of the columns in Q and rows in R to\n",
    "    impose positive diagonal of Q\n",
    "    \"\"\"\n",
    "\n",
    "    D = diag_sign(Q)\n",
    "\n",
    "    Q[:, :] = Q @ D\n",
    "    R[:, :] = D @ R\n",
    "\n",
    "    return Q, R\n",
    "\n",
    "#Q, R = adjust_sign(*QR_Decomposition(matrix))\n",
    "Q, R = QR_Decomposition(matrix)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.26726124 -0.23911405  0.10079249]\n",
      " [ 0.80178373 -0.76516496  0.89273344]\n",
      " [-0.53452248  0.59778512 -0.43916726]]\n",
      "[[ 1.         -0.99693232  0.97746184]\n",
      " [-0.99693232  1.         -0.9697169 ]\n",
      " [ 0.97746184 -0.9697169   1.        ]]\n",
      "-0.9697168997448606\n",
      "[[ 1.   1.  -3. ]\n",
      " [ 3.   2.   1. ]\n",
      " [-2.   0.5  2.5]]\n",
      "[[-0.2152872  -1.10392428  0.59880966]\n",
      " [-0.90353626 -3.25127103  1.99635033]\n",
      " [ 0.57683964  2.36082597 -1.36305561]]\n"
     ]
    }
   ],
   "source": [
    "def QRFactorization(A):\n",
    "    # =============================================================================\n",
    "    # A is a Numpy array that represents a matrix of dimension m x n.\n",
    "    # QRFactorization returns matrices Q and R such that A=QR, Q is orthogonal\n",
    "    # and R is upper triangular.  The factorization is carried out using classical\n",
    "    # Gram-Schmidt and the results may suffer due to numerical instability.\n",
    "    # QRFactorization may not return correct results if the columns of A are \n",
    "    # linearly dependent.\n",
    "    # =============================================================================\n",
    "\n",
    "    # Check shape of A\n",
    "    if (A.shape[0] < A.shape[1]):\n",
    "        print(\"A must have more rows than columns for QR factorization.\")\n",
    "        return\n",
    "    \n",
    "    (m, n) = A.shape\n",
    "    Q = np.empty((m, n))\n",
    "\n",
    "    for i in range(n):\n",
    "        q = A[:, i] # i-th column of A\n",
    "\n",
    "        for j in range(i):\n",
    "            q = q - np.dot(A[:, j], A[:, i]) * A[:, j]\n",
    "        \n",
    "        if np.array_equal(q, np.zeros(q.shape)):\n",
    "            raise np.linalg.LinAlgError(\"The column vectors are not linearly independent\")\n",
    "        \n",
    "        # normalize q\n",
    "        q = q / np.linalg.norm(q)\n",
    "        \n",
    "        # write the vector back in the matrix\n",
    "        Q[:, i] = q\n",
    "\n",
    "    R =  A @ Q.T\n",
    "    \n",
    "    return (Q,R)\n",
    "\n",
    "matrix = np.array([\n",
    "            [1.0, 1.0, -3.0],\n",
    "            [3.0, 2.0, 1.0],\n",
    "            [-2.0, 0.5, 2.5]\n",
    "        ])\n",
    "Q, R = QRFactorization(matrix)\n",
    "print(Q)\n",
    "print(Q.T @ Q)\n",
    "print(Q[:, 1] @ Q[:, 2])\n",
    "print(matrix)\n",
    "print(Q @ R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24199181180238022\n",
      "[[ 1.00000000e+00  7.74228433e-01  5.49691653e-17 -5.62801120e-01\n",
      "  -1.88215060e-01]\n",
      " [ 7.74228433e-01  2.08278638e+00  7.58773016e-01 -9.91059306e-01\n",
      "  -5.18531647e-01]\n",
      " [ 5.49691653e-17  7.58773016e-01  1.58256254e+00 -1.59966794e-01\n",
      "  -3.18620692e-01]\n",
      " [-5.62801120e-01 -9.91059306e-01 -1.59966794e-01  5.56211483e-01\n",
      "   2.41991812e-01]\n",
      " [-1.88215060e-01 -5.18531647e-01 -3.18620692e-01  2.41991812e-01\n",
      "   1.52044189e-01]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def cgs(A):\n",
    "    \"\"\"Classical Gram-Schmidt (CGS) algorithm\"\"\"\n",
    "    m, n = A.shape\n",
    "    R = np.zeros((n, n))\n",
    "    Q = np.empty((m, n))\n",
    "    R[0, 0] = linalg.norm(A[:, 0])\n",
    "    Q[:, 0] = A[:, 0] / R[0, 0]\n",
    "    for k in range(1, n):\n",
    "        R[:k-1, k] = np.dot(Q[:m, :k-1].T, A[:m, k])\n",
    "        z = A[:m, k] - np.dot(Q[:m, :k-1], R[:k-1, k])\n",
    "        R[k, k] = linalg.norm(z) ** 2\n",
    "        Q[:m, k] = z / R[k, k]\n",
    "        \n",
    "    print(Q[:, k] @ Q[:, k-1])\n",
    "    return Q, R\n",
    "\n",
    "n = 5\n",
    "X = np.random.random((n, n))\n",
    "# import rogues\n",
    "#    X = rogues.hilb(n)\n",
    "Q, R = cgs(X)\n",
    "print(Q.T@Q)\n",
    "assert np.allclose(np.dot(Q, R), X)\n",
    "#print(linalg.norm(np.dot(Q.T, Q) - np.eye(5), np.inf)\n",
    "\n",
    "\n",
    "def qr_mgs_decompose(matrix: np.array) -> (np.array, np.array):\n",
    "    \"\"\"\n",
    "    For n x m matrix return Q1 and R1 components of QR decomposition using\n",
    "    the modified Gram-Schmidt process, where R1 is n x n upper triangular\n",
    "    and Q1 is m x n and have orthogonal columns.\n",
    "    \"\"\"\n",
    "    n = matrix.shape[1]\n",
    "    q1 = np.array(matrix, dtype='float64')\n",
    "    r1 = np.zeros((n, n))\n",
    "    for k in range(n):\n",
    "        a_k = q1[..., k]\n",
    "        r1[k,k] = np.linalg.norm(a_k)\n",
    "        a_k /= r1[k, k]\n",
    "        for i in range(k+1, n):\n",
    "            a_i = q1[..., i]\n",
    "            r1[k,i] = np.transpose(a_k) @ a_i\n",
    "            a_i -= r1[k, i] * a_k\n",
    "    return q1, r1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[60. 91. 26.]\n",
      " [60.  3. 75.]\n",
      " [45. 90. 31.]]\n",
      "[[ 1.30417482 -0.07492098  0.88989461]\n",
      " [-0.07492098  0.95884056  0.19418816]\n",
      " [ 0.88989461  0.19418816  0.73698462]]\n"
     ]
    }
   ],
   "source": [
    "def qr_factorization(A):\n",
    "    m, n = A.shape\n",
    "    Q = np.zeros((m, n))\n",
    "    R = np.zeros((n, n))\n",
    "\n",
    "    for j in range(n):\n",
    "        v = A[:, j]\n",
    "\n",
    "        for i in range(j - 1):\n",
    "            q = Q[:, i]\n",
    "            R[i, j] = q.dot(v)\n",
    "            v = v - R[i, j] * q\n",
    "\n",
    "        norm = np.linalg.norm(v)\n",
    "        Q[:, j] = v / norm\n",
    "        R[j, j] = norm\n",
    "    return Q, R\n",
    "\n",
    "\n",
    "matrix = np.array([[60, 91, 26], [60, 3, 75], [45, 90, 31]])\n",
    "Q, R = qr_factorization(matrix)\n",
    "\n",
    "print(np.around(Q @ R))\n",
    "print(Q @ Q.T)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (b) (a+b 3.5 pts)\n",
    "Let $H$ be a Hilbert matrix of size $n$ (see Computer Problem 2.6). Study the quality of the QR decompositions obtained using the two methods of part (a), specifically the loss of orthogonality. In order to do so, plot the quantity $\\| I - Q^T Q \\|$ as a function of $n$ on a log scale. Vary $n$ from $2$ to $12$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classical Gram-Schmidt algorithm is not ideal for numerical calcula-\n",
    "tions since it is known to be unstable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (c) (1.5 pts)\n",
    "Try applying the classical procedure twice. Plot again the loss of orthogonality when computing the QR decomposition of the Hilbert matrix of size $n$ as in (b).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (d) (2 pts)\n",
    "Implement the Householder method for computing the QR decomposition. Remember to include a short documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def householder_qr(A):\n",
    "    # YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (e) (2 pts)\n",
    "Perform the analysis of (b) for the Householder method. Discuss the differences between all the methods you have tested so far. Look online and/or in books for information about the accuracy of the different methods and include this in your explanations (with reference).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
